{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 4 HW:  Analysis of NASA weblogs from 1995\n",
    "\n",
    "## Tuples\n",
    "\n",
    "Before we begin:  another built-in Python datatype that you will encounter is the *tuple*.  A tuple looks a LOT like a list, except that it is denoted with parentheses instead of brackets.  Elements are indexed in exactly the same way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'zero'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mytuple = (\"zero\", \"one\", \"two\")\n",
    "mytuple[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only difference is that tuples have a FIXED LENGTH (once created, we cannot add or remove elements), and they are IMMUTABLE (once created, the elements cannot be changed - with some caveats that I want to ignore right now).\n",
    "\n",
    "They are especially well-suited for situations where you want to bundle a small (e.g. 3) group of elements together.  In these situations they are much more efficient than lists.\n",
    "\n",
    "Tuples with only a single element need an extra comma \",\" after the element.  Can you figure out why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_a_tuple = (9)\n",
    "type(not_a_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_tuple = (9,)\n",
    "type(a_tuple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing log entries using regular expressions\n",
    "\n",
    "*Parsing* is the act of extracting structured information from strings.  In this homework we will use *regular expressions* to parse each log entry.\n",
    "\n",
    "Recall that in week 2 we used regular expressions to clean up our tweets (see Python video tutorials).  There we only did simple substitutions (finding patterns and replacing with `' '`).\n",
    "\n",
    "A nice tutorial is here: https://www.machinelearningplus.com/python/python-regex-tutorial-examples/ \n",
    "\n",
    "Full documentation here:  https://docs.python.org/3/howto/regex.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Here is an example entry from the log\n",
    "# let's practice extracting the following fields from it (already described):\n",
    "# requesting_host\n",
    "# user_identity\n",
    "# user_local_identity\n",
    "# timestamp\n",
    "# requested_resource\n",
    "# return_code\n",
    "# bytes_transferred\n",
    "\n",
    "logentry = 'maynard.isi.uconn.edu - - [28/Jul/1995:13:32:22 -0400] \"GET /images/shuttle-patch-logo.gif HTTP/1.0\" 200 891'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You need to write a regular expression that extracts the fields into variables\n",
    "# YOUR CODE GOES HERE\n",
    "logpattern = '(\\S+)\\s+(\\S+)\\s+(\\S+)\\s+\\[(.+)]\\s\\\"(.+)\\\"\\s+(\\d+)\\s+(\\d+)'\n",
    "logregex = re.compile(logpattern)\n",
    "matches = logregex.match(logentry)\n",
    "requesting_host, user_identity, user_local_identity, timestamp, requested_resource, return_code, bytes_transferred = matches.groups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert requesting_host == 'maynard.isi.uconn.edu'\n",
    "assert user_identity == '-'\n",
    "assert user_local_identity == '-'\n",
    "assert timestamp == '28/Jul/1995:13:32:22 -0400'\n",
    "assert requested_resource == 'GET /images/shuttle-patch-logo.gif HTTP/1.0'\n",
    "assert return_code == '200'\n",
    "assert bytes_transferred == '891'\n",
    "# TODO test what happens when bytes_transferred is a '-'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing Timestamps\n",
    "\n",
    "The timestamp itself has some further structure that we want to extract.  Let's try using another regex to split up the timestamp string.  It is formatted in the following way: `Day/Month/Year:Hour:Minute:Second Timezone`.\n",
    "\n",
    "Write a regular expression that parses the timestamp string (from the example above):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tspattern = '(\\d+)/(\\w+)/(\\d+):(\\d+):(\\d+):(\\d+)\\s+(\\S+)'\n",
    "tsregex = re.compile(tspattern)\n",
    "matches = tsregex.match(timestamp)\n",
    "day, month, year, hour, minute, second, timezone = matches.groups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert day == '28'\n",
    "assert month == 'Jul'\n",
    "assert year == '1995'\n",
    "assert hour == '13'\n",
    "assert minute == '32'\n",
    "assert second == '22'\n",
    "assert timezone == '-0400'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that parsing this timestamp using a regex is just the beginning!  In order to get something useful (i.e. dates and times that you can do ARITHMETIC on) you would have to translate the month string from `'Jul'` to the number `7`.  But what if somebody changes the log format to write out `'July'` instead of `'Jul'`?  Are you going to handle that case as well?  What if somebody changes the log system to spew month strings that are in French?\n",
    "\n",
    "What if somebody starts spelling out timezones, e.g. `'US Mountain'`?  \n",
    "\n",
    "Your head should start spinning now.  All of this CAN be done with regex, but with a lot of extra logic on top to check various cases.\n",
    "\n",
    "Worse, you need to start understanding the intricacies of the calendar if you want to answer questions like:  how many days are in between `December 7, 1941` and `January 1, 2017`.  Start thinking about leap days!  Did you know there are leap seconds as well?\n",
    "\n",
    "Fortunately, Python has a `datetime` module that is meant to simplify life (note: `datetime` does NOT handle leap seconds it turns out, but ignore that little nasty).  Let it do all of the hard date and time arithmetic for you!  Here is a tutorial to get you started: https://www.guru99.com/date-time-and-datetime-classes-in-python.html\n",
    "\n",
    "Let's abandon the regex approach to timestamps.  Instead, `datetime` comes with a smart way to parse timestamp strings called `strptime`.  Use that instead! (described in the tutorial).\n",
    "\n",
    "One thing to keep in mind:  all sane systems measure time using UTC (Coordinated Universal Time).  Roughly, this is just Greenwich Mean Time (with some subtleties).  The timezone will come formatted like `-0400` (4 hours behind UTC), or `+0800` (8 hours ahead of UTC).\n",
    "\n",
    "Your task:  create a `datetime` object that holds the date and time that you extracted above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timezone, timedelta\n",
    "\n",
    "# YOUR CODE GOES HERE\n",
    "dt = datetime.strptime(timestamp, \"%d/%b/%Y:%H:%M:%S %z\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert dt == datetime(1995, 7, 28, 13, 32, 22, tzinfo=timezone(-timedelta(hours=4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Spark to load weblogs into RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "\n",
    "sc = SparkContext('local', 'NASA_weblog_analysis') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.parallelize([1,2,3,4])\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
